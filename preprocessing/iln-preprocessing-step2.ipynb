{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## todo list:\n",
    "- Consider the bssids observed on test for deciding the set of bssids for the whole site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from glob import glob\n",
    "from joblib import Parallel,delayed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../utils/\")\n",
    "from iln_io_f import read_data_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob(\"../data/train/*.parquet\")\n",
    "test_files  = glob(\"../data/test/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/bssid_by_site.yml\", \"r\") as file:\n",
    "    bssid_by_site = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Creating dataset-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../data/ds1/train\n",
    "!mkdir -p ../data/ds1/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum percentaje of observation to be considered as top seen bssid\n",
    "MIN_PERC = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_seq_nbr(ts_serie):\n",
    "    \"\"\"\n",
    "    Function to calculate the sequence number: for each path, the \n",
    "    sequence number corresponds to the ordered index of each \n",
    "    waypoint observation\n",
    "    \"\"\"\n",
    "    mapping = {v:i for i,v in enumerate(np.sort(ts_serie.unique()))}\n",
    "    return ts_serie.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing site 1/24: 5da1389e4db8ce0c98bd0547\n",
      "Min number of observations: 315 from: 6312\n",
      "Selected 225 bssids from 1021 (22.04%)\n",
      "rows with no signal removed in dataset: 6\n",
      "\n",
      "Processing site 2/24: 5d27099f03f801723c32511d\n",
      "Min number of observations: 212 from: 4251\n",
      "Selected 554 bssids from 925 (59.89%)\n",
      "\n",
      "Processing site 3/24: 5d2709b303f801723c327472\n",
      "Min number of observations: 767 from: 15358\n",
      "Selected 667 bssids from 1913 (34.87%)\n",
      "rows with no signal removed in dataset: 786\n",
      "\n",
      "Processing site 4/24: 5dc8cea7659e181adb076a3f\n",
      "Min number of observations: 782 from: 15655\n",
      "Selected 716 bssids from 4864 (14.72%)\n",
      "rows with no signal removed in dataset: 468\n",
      "\n",
      "Processing site 5/24: 5d2709c303f801723c3299ee\n",
      "Min number of observations: 504 from: 10083\n",
      "Selected 2159 bssids from 5831 (37.03%)\n",
      "\n",
      "Processing site 6/24: 5d2709d403f801723c32bd39\n",
      "Min number of observations: 501 from: 10027\n",
      "Selected 564 bssids from 2139 (26.37%)\n",
      "\n",
      "Processing site 7/24: 5d27097f03f801723c320d97\n",
      "Min number of observations: 525 from: 10507\n",
      "Selected 776 bssids from 2490 (31.16%)\n",
      "rows with no signal removed in dataset: 3151\n",
      "\n",
      "Processing site 8/24: 5d27075f03f801723c2e360f\n",
      "Min number of observations: 1183 from: 23666\n",
      "Selected 1585 bssids from 7029 (22.55%)\n",
      "rows with no signal removed in dataset: 6280\n",
      "\n",
      "Processing site 9/24: 5d27096c03f801723c31e5e0\n",
      "Min number of observations: 455 from: 9100\n",
      "Selected 516 bssids from 4964 (10.39%)\n",
      "\n",
      "Processing site 10/24: 5c3c44b80379370013e0fd2b\n",
      "Min number of observations: 486 from: 9737\n",
      "Selected 1354 bssids from 3063 (44.21%)\n",
      "\n",
      "Processing site 11/24: 5da138364db8ce0c98bc00f1\n",
      "Min number of observations: 138 from: 2767\n",
      "Selected 368 bssids from 822 (44.77%)\n",
      "\n",
      "Processing site 12/24: 5da958dd46f8266d0737457b\n",
      "Min number of observations: 757 from: 15148\n",
      "Selected 1292 bssids from 3499 (36.92%)\n",
      "rows with no signal removed in dataset: 8\n",
      "\n",
      "Processing site 13/24: 5a0546857ecc773753327266\n",
      "Min number of observations: 464 from: 9296\n",
      "Selected 1701 bssids from 3397 (50.07%)\n",
      "\n",
      "Processing site 14/24: 5da138314db8ce0c98bbf3a0\n",
      "Min number of observations: 450 from: 9012\n",
      "Selected 787 bssids from 1212 (64.93%)\n",
      "\n",
      "Processing site 15/24: 5d2709bb03f801723c32852c\n",
      "Min number of observations: 860 from: 17203\n",
      "Selected 969 bssids from 2452 (39.52%)\n",
      "rows with no signal removed in dataset: 5060\n",
      "\n",
      "Processing site 16/24: 5da1383b4db8ce0c98bc11ab\n",
      "Min number of observations: 659 from: 13196\n",
      "Selected 746 bssids from 1525 (48.92%)\n",
      "\n",
      "Processing site 17/24: 5da1382d4db8ce0c98bbe92e\n",
      "Min number of observations: 449 from: 8999\n",
      "Selected 1393 bssids from 2862 (48.67%)\n",
      "rows with no signal removed in dataset: 10\n",
      "\n",
      "Processing site 18/24: 5d2709a003f801723c3251bf\n",
      "Min number of observations: 197 from: 3940\n",
      "Selected 653 bssids from 1252 (52.16%)\n",
      "\n",
      "Processing site 19/24: 5da138754db8ce0c98bca82f\n",
      "Min number of observations: 359 from: 7188\n",
      "Selected 496 bssids from 1627 (30.49%)\n",
      "rows with no signal removed in dataset: 1566\n",
      "\n",
      "Processing site 20/24: 5da138b74db8ce0c98bd4774\n",
      "Min number of observations: 869 from: 17382\n",
      "Selected 1239 bssids from 3535 (35.05%)\n",
      "rows with no signal removed in dataset: 3619\n",
      "\n",
      "Processing site 21/24: 5d2709e003f801723c32d896\n",
      "Min number of observations: 552 from: 11042\n",
      "Selected 485 bssids from 1309 (37.05%)\n",
      "\n",
      "Processing site 22/24: 5da138764db8ce0c98bcaa46\n",
      "Min number of observations: 471 from: 9420\n",
      "Selected 703 bssids from 1888 (37.24%)\n",
      "\n",
      "Processing site 23/24: 5dbc1d84c1eb61796cf7c010\n",
      "Min number of observations: 808 from: 16174\n",
      "Selected 1537 bssids from 4519 (34.01%)\n",
      "\n",
      "Processing site 24/24: 5da138274db8ce0c98bbd3d2\n",
      "Min number of observations: 133 from: 2662\n",
      "Selected 248 bssids from 490 (50.61%)\n",
      "CPU times: user 3min 16s, sys: 2min 17s, total: 5min 33s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_sites = list()\n",
    "top_seen_bssids_by_site = dict()\n",
    "\n",
    "for i,file in enumerate(train_files):\n",
    "    \n",
    "    site_id = file.split(\"/\")[-1].split(\".\")[0]\n",
    "    all_sites.append(site_id)\n",
    "    \n",
    "    print(f\"\\nProcessing site {i+1}/{len(train_files)}: {site_id}\")\n",
    "\n",
    "    all_bssids = bssid_by_site[site_id]\n",
    "    df = pd.read_parquet(file)\n",
    "    df[\"site\"] = site_id\n",
    "    df[\"wifi_time_diff\"] = np.abs(df.wifi_time_delta)\n",
    "    df[\"seq_nbr\"] = df.groupby(\"path\")[\"timestamp\"].apply(compute_seq_nbr)\n",
    "    \n",
    "    # selects the top seen bssids for the site\n",
    "    n_wifi_obs = len(df.loc[:,[\"path\",\"timestamp_wifi\"]].drop_duplicates())\n",
    "    min_obs = int(n_wifi_obs*MIN_PERC)\n",
    "    count_by_bssid = (df.query(\"seq_nbr == 1\")[all_bssids] > -999).sum(axis=0)\n",
    "    top_seen_bssids = count_by_bssid[count_by_bssid > min_obs].index.tolist()\n",
    "    top_seen_bssids_by_site[site_id] = top_seen_bssids\n",
    "    bssids_to_remove = list(set(all_bssids)-set(top_seen_bssids))\n",
    "    print(\"Min number of observations:\", min_obs, \"from:\", n_wifi_obs)\n",
    "        \n",
    "    n_top = len(top_seen_bssids)\n",
    "    n_all = len(all_bssids)\n",
    "    print(f\"Selected {n_top} bssids from {n_all} ({100*n_top/n_all:.2f}%)\")\n",
    "    \n",
    "    df.drop(bssids_to_remove, axis=1, inplace=True)\n",
    "    # sanity check\n",
    "    if (df[top_seen_bssids] == -999).all(axis=0).any():\n",
    "        cols_to_drop = df[top_seen_bssids].columns[(df[top_seen_bssids] == -999).all(axis=0)]\n",
    "        df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "        print(\"columns with no signal removed in dataset:\", len(cols_to_drop))\n",
    "    if (df[top_seen_bssids] == -999).all(axis=1).any():\n",
    "        idx_to_drop = df.index[(df[top_seen_bssids] == -999).all(axis=1)]\n",
    "        df.drop(idx_to_drop, inplace=True)\n",
    "        print(\"rows with no signal removed in dataset:\", len(idx_to_drop))\n",
    "        \n",
    "    df.to_parquet(f\"../data/ds1/train/{site_id}.parquet\", index=False)\n",
    "    del df; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 176/626 [00:22<00:57,  7.80it/s]/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "100%|██████████| 626/626 [01:21<00:00,  7.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# reads test files in parallel\n",
    "with Parallel(n_jobs=8) as parallel:\n",
    "    delayed_func = delayed(pd.read_parquet)\n",
    "    test_dataframes = parallel(delayed_func(f) for f in tqdm(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing site 1/24: 5da1389e4db8ce0c98bd0547\n",
      "columns with no signal in dataset: 6 from 225\n",
      "\n",
      "Processing site 2/24: 5d27099f03f801723c32511d\n",
      "columns with no signal in dataset: 100 from 554\n",
      "\n",
      "Processing site 3/24: 5d2709b303f801723c327472\n",
      "columns with no signal in dataset: 34 from 667\n",
      "rows with no signal removed in dataset: 544 from 60310\n",
      "\n",
      "Processing site 4/24: 5dc8cea7659e181adb076a3f\n",
      "columns with no signal in dataset: 1 from 716\n",
      "\n",
      "Processing site 5/24: 5d2709c303f801723c3299ee\n",
      "columns with no signal in dataset: 124 from 2159\n",
      "\n",
      "Processing site 6/24: 5d2709d403f801723c32bd39\n",
      "\n",
      "Processing site 7/24: 5d27097f03f801723c320d97\n",
      "columns with no signal in dataset: 48 from 776\n",
      "\n",
      "Processing site 8/24: 5d27075f03f801723c2e360f\n",
      "columns with no signal in dataset: 895 from 1585\n",
      "\n",
      "Processing site 9/24: 5d27096c03f801723c31e5e0\n",
      "\n",
      "Processing site 10/24: 5c3c44b80379370013e0fd2b\n",
      "columns with no signal in dataset: 601 from 1354\n",
      "\n",
      "Processing site 11/24: 5da138364db8ce0c98bc00f1\n",
      "columns with no signal in dataset: 43 from 368\n",
      "\n",
      "Processing site 12/24: 5da958dd46f8266d0737457b\n",
      "rows with no signal removed in dataset: 20 from 75967\n",
      "\n",
      "Processing site 13/24: 5a0546857ecc773753327266\n",
      "columns with no signal in dataset: 103 from 1701\n",
      "\n",
      "Processing site 14/24: 5da138314db8ce0c98bbf3a0\n",
      "columns with no signal in dataset: 5 from 787\n",
      "\n",
      "Processing site 15/24: 5d2709bb03f801723c32852c\n",
      "columns with no signal in dataset: 57 from 969\n",
      "\n",
      "Processing site 16/24: 5da1383b4db8ce0c98bc11ab\n",
      "columns with no signal in dataset: 34 from 746\n",
      "\n",
      "Processing site 17/24: 5da1382d4db8ce0c98bbe92e\n",
      "columns with no signal in dataset: 151 from 1393\n",
      "rows with no signal removed in dataset: 826 from 40908\n",
      "\n",
      "Processing site 18/24: 5d2709a003f801723c3251bf\n",
      "columns with no signal in dataset: 26 from 653\n",
      "\n",
      "Processing site 19/24: 5da138754db8ce0c98bca82f\n",
      "columns with no signal in dataset: 2 from 496\n",
      "\n",
      "Processing site 20/24: 5da138b74db8ce0c98bd4774\n",
      "columns with no signal in dataset: 20 from 1239\n",
      "\n",
      "Processing site 21/24: 5d2709e003f801723c32d896\n",
      "columns with no signal in dataset: 5 from 485\n",
      "\n",
      "Processing site 22/24: 5da138764db8ce0c98bcaa46\n",
      "columns with no signal in dataset: 4 from 703\n",
      "\n",
      "Processing site 23/24: 5dbc1d84c1eb61796cf7c010\n",
      "\n",
      "Processing site 24/24: 5da138274db8ce0c98bbd3d2\n",
      "columns with no signal in dataset: 12 from 248\n"
     ]
    }
   ],
   "source": [
    "for i,site_id in enumerate(all_sites):\n",
    "    \n",
    "    print(f\"\\nProcessing site {i+1}/{len(all_sites)}: {site_id}\")\n",
    "    \n",
    "    all_bssids = bssid_by_site[site_id]\n",
    "    top_seen_bssids = top_seen_bssids_by_site[site_id] \n",
    "    bssids_to_remove = list(set(all_bssids)-set(top_seen_bssids))\n",
    "    \n",
    "    df = pd.concat(filter(lambda x: x.site.unique()[0] == site_id, test_dataframes), axis=0, ignore_index=True)\n",
    "    df.drop(bssids_to_remove, axis=1, inplace=True)\n",
    "    n_pred_points = df.site_path_timestamp.nunique()\n",
    "    \n",
    "    # sanity check\n",
    "    if (df[top_seen_bssids] == -999).all(axis=0).any():\n",
    "        cols_to_drop = df[top_seen_bssids].columns[(df[top_seen_bssids] == -999).all(axis=0)]\n",
    "        # columns are not dropped beacuse can be useful for fitting the training set\n",
    "        #df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "        print(f\"columns with no signal in dataset: {len(cols_to_drop)} from {len(top_seen_bssids)}\")\n",
    "        \n",
    "        # updates the top_seen_bssids\n",
    "        #top_seen_bssids = set(top_seen_bssids) - set(cols_to_drop)\n",
    "        #top_seen_bssids_by_site[site_id] = top_seen_bssids\n",
    "        \n",
    "    if (df[top_seen_bssids] == -999).all(axis=1).any():\n",
    "        idx_to_drop = df.index[(df[top_seen_bssids] == -999).all(axis=1)]\n",
    "        df.drop(idx_to_drop, inplace=True)\n",
    "        print(f\"rows with no signal removed in dataset: {len(idx_to_drop)} from {len(df)}\")\n",
    "        \n",
    "        # verifies if there are no missing prediction points\n",
    "        assert n_pred_points == df.site_path_timestamp.nunique(), \"Missing prediction points\"\n",
    "    \n",
    "    df[\"wifi_time_diff\"] = np.abs(df.wifi_time_delta)\n",
    "    df[\"seq_nbr\"] = df.groupby(\"path\")[\"timestamp\"].apply(compute_seq_nbr)\n",
    "    \n",
    "    df.to_parquet(f\"../data/ds1/test/{site_id}.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets version -r zip -p ../data/ds1 -m \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## dataset-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
